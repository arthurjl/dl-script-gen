{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape data from pbs documentaries here\n",
    "https://www.pbs.org/wgbh/nova/transcripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic(transcript_urls, savepath):\n",
    "    result = \"\"\n",
    "    for single_url in tqdm(transcript_urls):\n",
    "        single_page = requests.get(single_url)\n",
    "        single_soup = BeautifulSoup(single_page.content, 'html.parser')\n",
    "\n",
    "        # Remove unwanted data (note the comma!)\n",
    "        to_remove = single_soup.select('#d_feature_copy .caption,' +  # remove caption\n",
    "                                       '#d_feature_copy h2 ~ p') # remove credits\n",
    "        for item_to_remove in to_remove:\n",
    "            item_to_remove.extract()\n",
    "\n",
    "        for line in single_soup.select('#d_feature_copy p'):\n",
    "            result += \" \".join(line.text.split()) + \"\\n\"\n",
    "\n",
    "    with open(savepath, 'w', encoding=\"UTF\") as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:10<00:00,  5.06it/s]\n"
     ]
    }
   ],
   "source": [
    "save_topic(transcript_urls, 'data/nova_anthropology_transcripts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_anth.html: Total of 49 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:10<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_disa.html: Total of 24 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_eart.html: Total of 45 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:12<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_expl.html: Total of 35 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:07<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_flig.html: Total of 21 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:04<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_heal.html: Total of 60 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:24<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_hist.html: Total of 87 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:22<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_inve.html: Total of 29 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:09<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_natu.html: Total of 65 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:19<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_phys.html: Total of 42 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:10<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_spac.html: Total of 35 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:09<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/int_tech.html: Total of 94 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:27<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def by_topic():\n",
    "    URL_BASE = 'https://www.pbs.org'\n",
    "    pairs = [\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_anth.html', 'data/nova_anthropology_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_disa.html', 'data/nova_disaster_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_eart.html', 'data/nova_earth_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_expl.html', 'data/nova_exploration_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_flig.html', 'data/nova_flight_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_heal.html', 'data/nova_health_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_hist.html', 'data/nova_history_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_inve.html', 'data/nova_investigations_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_natu.html', 'data/nova_nature_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_phys.html', 'data/nova_physicsmath_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_spac.html', 'data/nova_space_transcripts.txt'),\n",
    "        ('https://www.pbs.org/wgbh/nova/transcripts/int_tech.html', 'data/nova_technology_transcripts.txt'),\n",
    "    ]\n",
    "    for page_pair in pairs:\n",
    "        URL = page_pair[0]\n",
    "        SAVEPATH = page_pair[1]\n",
    "        \n",
    "        page = requests.get(URL)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # soup.find() is one interface\n",
    "        # soup.select uses css selection which I'm more familiar with\n",
    "        transcript_urls = [URL_BASE + a['href'] for a in soup.select('#d_feature_copy p a')]\n",
    "        print(f\"{URL}: Total of {len(transcript_urls)} links to scrape\")\n",
    "        save_topic(transcript_urls, SAVEPATH)\n",
    "by_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(transcript_urls):\n",
    "    result = \"\"\n",
    "    for single_url in tqdm(transcript_urls):\n",
    "        single_page = requests.get(single_url)\n",
    "        single_soup = BeautifulSoup(single_page.content, 'html.parser')\n",
    "\n",
    "        # Remove unwanted data (note the comma!)\n",
    "        to_remove = single_soup.select('#d_feature_copy .caption,' +  # remove caption\n",
    "                                       '#d_feature_copy h2 ~ p') # remove credits\n",
    "        for item_to_remove in to_remove:\n",
    "            item_to_remove.extract()\n",
    "\n",
    "        for line in single_soup.select('#d_feature_copy p'):\n",
    "            result += \" \".join(line.text.split()) + \"\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_1995.html: Total of 1 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_1996.html: Total of 9 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_1997.html: Total of 33 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:06<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_1998.html: Total of 19 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:06<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_1999.html: Total of 19 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:03<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2000.html: Total of 21 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:04<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2001.html: Total of 20 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2002.html: Total of 15 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2003.html: Total of 15 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2004.html: Total of 14 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:03<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2005.html: Total of 18 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2006.html: Total of 19 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2007.html: Total of 18 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:06<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2008.html: Total of 23 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:07<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2009.html: Total of 20 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:37<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pbs.org/wgbh/nova/transcripts/year_2010.html: Total of 6 links to scrape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def by_year():\n",
    "    URL_BASE = 'https://www.pbs.org'\n",
    "    urls = ['https://www.pbs.org/wgbh/nova/transcripts/year_1995.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_1996.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_1997.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_1998.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_1999.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2000.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2001.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2002.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2003.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2004.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2005.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2006.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2007.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2008.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2009.html',\n",
    "            'https://www.pbs.org/wgbh/nova/transcripts/year_2010.html'\n",
    "           ]\n",
    "    result = \"\"\n",
    "    for URL in urls:    \n",
    "        page = requests.get(URL)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # soup.find() is one interface\n",
    "        # soup.select uses css selection which I'm more familiar with\n",
    "        transcript_urls = [URL_BASE + a['href'] for a in soup.select('#d_feature_copy p a')]\n",
    "        print(f\"{URL}: Total of {len(transcript_urls)} links to scrape\")\n",
    "        result += get_transcript(transcript_urls) + \"\\n\"\n",
    "        \n",
    "    with open(\"data/nova_ALL_transcripts.txt\", 'w', encoding=\"UTF\") as f:\n",
    "        f.write(result)\n",
    "        \n",
    "by_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
